# üìä Comparatif Approche Map-Reduce vs Approche Na√Øve

## ‚öôÔ∏è Protocole de Test

- **Dataset utilis√©** : `csebuetnlp/xlsum` - 100 articles en **fran√ßais**.
- **M√©thode Na√Øve** :
  - **Prompt** :
    ```jinja
    Vous √™tes un expert en r√©sum√©. R√©sumez le texte ci-dessous en conservant son sens principal et la langue du texte.
    {% if size %}
    Le r√©sum√© doit faire moins de {{ size }} mots.
    {% endif %}
    {% if language %}
    Le r√©sum√© doit √™tre en {{ language }}.
    {% endif %}
    Texte : {{ text }}
    ```
  - **Nombre d'appels API** = **100** (1 appel par article).
  - **Taille du r√©sum√©** : D√©finie selon la variable `size` si sp√©cifi√©e.

- **M√©thode Map-Reduce** :
  - **Param√®tres** :
    ```python
    MAP_PROMPT = "R√©digez un r√©sum√© concis des √©l√©ments suivants :\n\n{context}"

    REDUCE_PROMPT = """
    Voici une s√©rie de r√©sum√©s:
    {docs}
    Rassemblez ces √©l√©ments et faites-en un r√©sum√© final et consolid√© dans {language} en {size} mots au maximum. R√©digez uniquement en {language}.
    """
    ParamsSummarize:
        method: "map_reduce"
        model: gemma3
        context_size: 10_000
        temperature: 0.0
        language: "French"
        size: 4000
    ```
  - **Processus** :
    - D√©coupage du texte si n√©cessaire (`context_size` 10k tokens max),
    - R√©sum√©s partiels (`MAP_PROMPT`),
    - R√©sum√© final consolid√© (`REDUCE_PROMPT`).
  - **Nombre d'appels API** = **30**.

---

## üìã Tableau Comparatif
| Crit√®re                        | Map-Reduce                               | Approche Na√Øve                         |
|---------------------------------|------------------------------------------|----------------------------------------|
| **Mod√®le utilis√©**              | gemma3                                   | gemma3                                 |
| **Nombre de textes √©valu√©s**     | 50                                       | 50                                     |
| **Nombre d'appels API**          | 150 (Map + Reduce)                       | 50 (1 appel par texte)                 |
| **Temps total de r√©sum√© (s)**    | 837.21                                   | 93.44                                  |
| **Temps moyen par pr√©diction (s)** | 16.74                                   | 1.87                                   |
| **M√©thode de traitement**        | Map-Reduce (d√©coupage + fusion)           | R√©sum√© direct                          |
| **ROUGE-1**                      | 0.0314                                   | 0.2194                                 |
| **ROUGE-2**                      | 0.0113                                   | 0.0586                                 |
| **ROUGE-L**                      | 0.0256                                   | 0.1315                                 |
| **ROUGE-Lsum**                   | 0.0282                                   | 0.1388                                 |
| **Pr√©cision BERTScore**           | 0.5859                                   | 0.6514                                 |
| **Rappel BERTScore**              | 0.6902                                   | 0.7248                                 |
| **F1 BERTScore**                  | 0.6335                                   | 0.6856                                 |

---


# üß† Analyse rapide

- **Qualit√© du r√©sum√©** :
  - Encore une fois, **l‚Äôapproche na√Øve** produit des r√©sum√©s **beaucoup plus proches** des r√©sum√©s de r√©f√©rence selon **ROUGE** et **BERTScore**.
  - **ROUGE-1** est environ **7 fois plus √©lev√©** pour l‚Äôapproche na√Øve.

- **Performance temporelle** :
  - L‚Äôapproche na√Øve est **9 fois plus rapide** en temps total.
  - **Map-Reduce** est extr√™mement co√ªteux ici : **plus de 14 minutes** contre **moins de 2 minutes** pour na√Øf !

- **Co√ªt en API** :
  - **150 appels API** pour 50 textes en Map-Reduce contre seulement **50** pour la m√©thode na√Øve.

- **Interpr√©tation** :
  - **Map-Reduce** est ici **inefficace** pour de petits textes comme ceux de `xlsum`.
