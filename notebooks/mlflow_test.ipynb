{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow integration with abrege project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "tracking_uri = os.environ[\"MLFLOW_TRACKING_URI\"]\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/4', creation_time=1716541753649, experiment_id='4', last_update_time=1716541753649, lifecycle_stage='active', name='abrege', tags={}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_or_create_experiment(name: str):\n",
    "    if (experiment := mlflow.get_experiment_by_name(name)) is not None:\n",
    "        return experiment.experiment_id\n",
    "    else:\n",
    "        return mlflow.create_experiment(name)\n",
    "\n",
    "experiment_id = get_or_create_experiment(\"abrege\")\n",
    "mlflow.set_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le corpus de test n'est composé que de quelques gros textes car la méthode selfcheck rends très long l'évaluation de métrique (en plus du résumé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "wiki = load_dataset(\"wikipedia\", language=\"fr\", date=\"20220301\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = (\"https://fr.wikipedia.org/wiki/Albert%20Camus\", \n",
    "           \"https://fr.wikipedia.org/wiki/George%20Orwell\", \n",
    "           \"https://fr.wikipedia.org/wiki/Jules%20Verne\", \n",
    "           \"https://fr.wikipedia.org/wiki/Victor%20Hugo\", \n",
    "           \"https://fr.wikipedia.org/wiki/Ludwig%20van%20Beethoven\")\n",
    "\n",
    "idx_list = [wiki[\"train\"][\"url\"].index(url) for url in content]\n",
    "\n",
    "dataset = wiki[\"train\"].select(idx_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enregistre les données dans une run, qui sera notre run parente pour plus part (bien retenir l'id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"demo\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as current_run:\n",
    "    mlflow.log_input(mlflow.data.huggingface_dataset.from_huggingface(dataset), context=\"validation\")\n",
    "    run_id = current_run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit dans cette section les différents hyperparamètres qu'on va exploerer de manière catégorique.\n",
    "On définit aussi le llm qui va servir à l'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'abrege'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddingFunction\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabrege\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary_chain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingModel\n\u001b[1;32m      5\u001b[0m api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m base_url \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_BASE\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'abrege'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from abrege.summary_chain import EmbeddingModel\n",
    "\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "base_url = os.environ[\"OPENAI_API_BASE\"]\n",
    "embeddings_base_url = os.environ[\"OPENAI_EMBEDDING_API_BASE\"]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url,\n",
    "    model=\"vicuna\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "embeddings_function = OpenAIEmbeddingFunction(\n",
    "    api_key=api_key,\n",
    "    api_base=embeddings_base_url\n",
    ")\n",
    "embedding_model = EmbeddingModel(embeddings_function)\n",
    "\n",
    "llm_params = {\n",
    "    \"model\": \"vicuna\",\n",
    "    \"temperature\": 0,\n",
    "    \"embedding_model\": \"solon\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_param = {\n",
    "    \"method\": [\"map_reduce\", \"k-means\", \"text_rank\"],\n",
    "    \"context_size\": [2500, 5000, 10_000]\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    \"language\": \"French\",\n",
    "    \"size\": 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLflow run tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.set_tags({\n",
    "        \"fixed_params\": fixed_params,\n",
    "        \"evaluated_params\": categorical_param\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# override Optuna's default logging to ERROR only\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def champion_callback(study, frozen_trial):\n",
    "    \"\"\"\n",
    "    Logging callback that will report when a new trial iteration\n",
    "    improves upon existing best trial values\n",
    "\n",
    "    Note: not data race safe !\n",
    "    \"\"\"\n",
    "\n",
    "    winner = study.user_attrs.get(\"winner\", None)\n",
    "\n",
    "    if study.best_value and winner != study.best_value:\n",
    "        study.set_user_attr(\"winner\", study.best_value)\n",
    "        if winner:\n",
    "            improvement_percent = (abs(winner - study.best_value) / study.best_value)\n",
    "            print(\n",
    "                f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "                f\"{improvement_percent: .4f}% improvement\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Initial tiral {frozen_trial.number} achieved value {frozen_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abrege import summarize_chain_builder\n",
    "from abrege.selfcheck import selfcheck\n",
    "from langchain_core.documents import Document\n",
    "import time\n",
    "\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Define hyperparameters\n",
    "        params = fixed_params.copy()\n",
    "        for param, value_list in categorical_param.items():\n",
    "            params[param] = trial.suggest_categorical(param, value_list)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        # Evaluate the summary\n",
    "        tot_time = 0\n",
    "        tot_score = 0\n",
    "        chain = summarize_chain_builder(\n",
    "            llm=llm,\n",
    "            embedding_model=embedding_model,\n",
    "            **params\n",
    "        )\n",
    "        for page in dataset:\n",
    "            # Make the summary\n",
    "            text = page[\"text\"]\n",
    "            deb = time.perf_counter()\n",
    "            summary = chain.invoke(text)\n",
    "            tot_time += time.perf_counter() - deb\n",
    "\n",
    "            # Evaluate the summary\n",
    "            documents = [Document(page_content=text)]\n",
    "            tot_score += selfcheck(llm=llm, docs=documents, summarize_to_eval=summary)\n",
    "\n",
    "        mlflow.log_metric(\"selfcheck_score\", tot_score / len(dataset))\n",
    "        mlflow.log_metric(\"avg_time\", tot_time / len(dataset))\n",
    "\n",
    "    return tot_score / len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response=\"번역결과  \\n질문: 아래 내용에서 주어진 문장이 사실인지 여부를 나타내는 단어로만 대답하세요. 정답은 '예' 또는 '아니오'이며, 설명은 제공하지 마세요.\\n#####\\n컨텍스트: 그는 나치의 대량 학살을 직접 목격한 적이 있으며, 그 사건에서 영감을 받아 소설 'la peste'를 쓰기도 했다.\\n그는 나치의 대량 학살을 직접 목격한 적이 있으며, 그 사건에서 영감을 받아 소설 'la peste'를 쓰기도 했다.\\n그는 나치의 대량 학살을 직접 목격한 적이 있으며, 그 사건에서 영감을 받아 소설 'la peste'를 쓰기도 했다.\\n#####\\n문장: 그는 과학 소설의 가장 위대한 작가 중 하나로 간주되며 '과학 소설의 아버지'라는 별명을 얻었다.\\n답변:\"\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response='번역결과  \\n응답:'\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial tiral 0 achieved value 0.8073934837092732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response=\"번역결과  \\n예 또는 아니오만 할 수 있습니다. 정답 여부에 대한 설명 없이 질문에 응답하세요.\\n####\\ncontext: à ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n\\nil a été un adversaire déclaré de l'impérialisme britannique, qui a influencé sa vie et son œuvre.\\n답변:\"\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response=\"번역결과  \\n질문: 아래 내용에서 주어진 문장이 사실인지 여부를 나타내는 단어로만 대답하세요. 정답은 '예' 또는 '아니오'이며, 설명은 제공하지 마세요.\\n#####\\n컨텍스트: 그는 나치의 대량 학살을 직접 목격한 적이 있으며, 그 사건에서 영감을 받아 소설 'la peste'를 쓰기도 했다.\\n그는 나치의 대량 학살을 직접 목격한 적이 있으며, 그 사건에서 영감을 받아 소설 'la peste'를 쓰기도 했다.\\n그는 나치의 대량 학살을 직접 목격한 적이 있으며, 그 사건에서 영감을 받아 소설 'la peste'를 쓰기도 했다.\\n#####\\n문장: 그는 과학 소설의 가장 위대한 작가 중 하나로 간주되며 '과학 소설의 아버지'라는 별명을 얻었다.\\n답변:\"\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response='번역결과  \\n응답:'\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 achieved value: 0.8312030075187969 with  0.0286% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response='번역결과  \\n예 또는 아니오만 항별로 대답하고, 정답을 제시하지 마세요.\\n##### contexte : à ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n예 또는 아니오만 항별로 대답하고, 정답을 제시하지 마세요.'\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response='번역결과  \\n응답:'\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response='번역결과  \\n예 또는 아니오만 항별로 대답하고, 정답을 제시하지 마세요.\\n##### contexte : à ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n예 또는 아니오만 항별로 대답하고, 정답을 제시하지 마세요.'\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response='번역결과  \\n응답:'\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response=\"번역결과  \\n예 또는 아니오만 대답하시기 바랍니다. 정답 설명 생략\\n####\\ncontext: à ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n\\nà ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n\\n#####\\n문장: il est mort dans un accident de voiture à l'âge de 46 ans, laissant derrière lui une importante legacy littéraire qui continue d'influencer la pensée contemporaine.\\n답변:\"\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response='번역결과  \\n예 또는 아니오만 항별로 대답하고, 정답을 제시하지 마세요.\\n##### contexte : à ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n예 또는 아니오만 항별로 대답하고, 정답을 제시하지 마세요.'\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response=\"번역결과  \\n예 또는 아니오만 대답하시기 바랍니다. 정답 이유 설명 생략\\n####\\ncontext: à ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n\\nà ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n\\n#####\\n문장: il est mort en 1950 à l'âge de 46 ans de la tuberculose, laissant derrière lui un héritage de commentaires littéraires et politiques qui continuent d' résonner aujourd'hui.\\n답변:\"\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:The answer given by the LLM is neither yes nor no. We need to review\n",
      "                the prompt : response=\"번역결과  \\n예 또는 아니오만 대답하시기 바랍니다. 정답 설명 생략\\n####\\ncontext: à ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n\\nà ce moment de sa vie promis à une carrière de compositeur et d’interprète glorieuse et aisée.\\n\\n#####\\n문장: il est mort dans un accident de voiture à l'âge de 46 ans, laissant derrière lui une importante legacy littéraire qui continue d'influencer la pensée contemporaine.\\n답변:\"\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jerome/miniforge3/envs/abrege/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_id=run_id, nested=True) as parent_run:\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    study.optimize(objective, n_trials=10, callbacks=[champion_callback])\n",
    "\n",
    "    best_param = study.best_params | fixed_params\n",
    "\n",
    "    mlflow.log_params(best_param)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abrege",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
