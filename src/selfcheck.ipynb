{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparer le score self check sur le map_reduce et le refine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_BASE= os.environ.get(\"OPENAI_API_BASE\", \"https://api-ai.numerique-interieur.com/v1\") \n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, openai_api_base=OPENAI_API_BASE, temperature=0, model=\"mixtral\")\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "#from langchain.llms.openai import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1, 2, 3], [3, 4]]==[[1, 2, 3], [5, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template_selfcheck = \"\"\"Is the sentence true, according to the context provided below? Answer only by Yes or No, without justification\n",
    "####\n",
    "CONTEXT: {context}\n",
    "\n",
    "#####\n",
    "SENTENCE: {text}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "custom_rag_prompt_selfcheck = PromptTemplate.from_template(template_selfcheck)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_selfcheck = (\n",
    "    {\"context\": retriever | format_docs, \"text\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt_selfcheck\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import cached_property\n",
    "import logging\n",
    "@dataclass\n",
    "class SelfCheckGPT():\n",
    "    llm: \"Model\"\n",
    "    documents: list\n",
    "    @staticmethod\n",
    "    def parse_response(response:str) -> int:\n",
    "        response = response.strip().lower()\n",
    "        if response.startswith(\"yes\"):\n",
    "            rep_int = 1\n",
    "        elif response.startswith(\"no\"):\n",
    "            rep_int = 0\n",
    "        else:\n",
    "            rep_int = 0.5\n",
    "            logging.warning(f\"{response}\")\n",
    "        return rep_int\n",
    "\n",
    "    @staticmethod\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"OrdalieTech/Solon-embeddings-base-0.1\") # plus de 13 min\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50, keep_separator=True, length_function=len)\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "        self.retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "\n",
    "    @cached_property\n",
    "    def rag_prompt(self):\n",
    "        template_selfcheck = (\"\"\"Is the sentence true, according to the context provided below? Answer only by Yes or No, without justification\n",
    "####\n",
    "CONTEXT: {context}\n",
    "\n",
    "#####\n",
    "SENTENCE: {text}\n",
    "\n",
    "Answer:\"\"\")\n",
    "        return PromptTemplate.from_template(template_selfcheck)\n",
    "\n",
    "    @cached_property\n",
    "    def rag_chain_selfcheck(self):\n",
    "        return (\n",
    "    {\"context\": self.retriever | SelfCheckGPT.format_docs, \"text\": RunnablePassthrough()}\n",
    "    | self.rag_prompt\n",
    "    | self.llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "\n",
    "    def get_array(self, text:str) -> list[int]:\n",
    "        import nltk\n",
    "        nltk.download('punkt')\n",
    "        sentences = nltk.tokenize.sent_tokenize(text)\n",
    "        responses = [self.rag_chain_selfcheck.invoke(sentence).strip().lower() for sentence in sentences]\n",
    "        return [SelfCheckGPT.parse_response(r) for r in responses]\n",
    "    \n",
    "    def eval_text(self, text:str) -> float:\n",
    "        return statistics.mean(self.get_array(text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.08"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.mean([1, 2.4, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark map_reduce vs refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Map\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{docs}\n",
    "Based on this list of docs, please identify the main themes \n",
    "Helpful Answer:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse, urlsplit\n",
    "parsed_url = urlparse(\"httzaps:/ez/www.exaezample.com/path?query=value#fragment\")\n",
    "parsed_url.scheme and parsed_url.netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, chain_type=\"map_reduce\"):\n",
    "    # Split the text into chunks\n",
    "    text_splitter = CharacterTextSplitter()\n",
    "    texts = text_splitter.split_text(text)\n",
    "    \n",
    "    # Create document objects for each chunk\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    \n",
    "    # Initialize the OpenAI model and load the summarize chain\n",
    "    chain = load_summarize_chain(llm, chain_type=chain_type)\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary = chain.run(docs)\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "text = Path(\"camus.txt\").read_text()\n",
    "map_reduce = summarize_text(text, chain_type=\"map_reduce\")\n",
    "refine = summarize_text(text, chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" In 1957, Albert Camus accepted the Nobel Prize in Literature, expressing gratitude and humility. He discussed the writer's role as a witness to the human condition, particularly during conflicts and oppression, highlighting the significance of truth and freedom. Camus cautioned writers against becoming preachers or moralizers, acknowledging his own limitations and dedicating the prize to less recognized peers. He reaffirmed his commitment to artistic integrity and truth-telling.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Albert Camus, accepting the Nobel Prize in Literature in 1957, expresses his gratitude and humility for the honor. He reflects on the role of the writer as a witness to the human condition, particularly during times of conflict and oppression. He emphasizes the importance of truth and freedom, and encourages writers to resist the temptation to become preachers or moralizers. Camus acknowledges his own limitations and debts, dedicating the prize to those who share in the same struggle but have not received similar recognition. He concludes by reaffirming his commitment to artistic integrity and truth-telling.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, -1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = SelfCheckGPT(llm, documents=[Document(page_content=text)])\n",
    "i.get_array(refine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, -1, -1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.get_array(map_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9486cf8afce647eb93bf23d9fd6f88a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231c203ecdb74cdaa5b2c0124b74f69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/944M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81b24044a9746ad9545b1f5c1b0b921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaf455f0e3347b79b3623321e6214ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/36.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1252fac2a145453d9b0a36f49dc1f8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/574226 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# poetry add datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ZhongshengWang/Alpaca-cnn-dailymail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "unstructured package not found, please install it with `pip install unstructured`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/abrege/lib/python3.12/site-packages/langchain_community/document_loaders/url.py:49\u001b[0m, in \u001b[0;36mUnstructuredURLLoader.__init__\u001b[0;34m(self, urls, continue_on_failure, mode, show_progress_bar, **unstructured_kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__version__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m __unstructured_version__\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unstructured'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.jesuismort.com/tombe/albert-camus#biographie\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredURLLoader\n\u001b[0;32m----> 3\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mUnstructuredURLLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43murls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43murl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/abrege/lib/python3.12/site-packages/langchain_community/document_loaders/url.py:54\u001b[0m, in \u001b[0;36mUnstructuredURLLoader.__init__\u001b[0;34m(self, urls, continue_on_failure, mode, show_progress_bar, **unstructured_kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__version \u001b[38;5;241m=\u001b[39m __unstructured_version__\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munstructured package not found, please install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install unstructured`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_mode(mode)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n",
      "\u001b[0;31mImportError\u001b[0m: unstructured package not found, please install it with `pip install unstructured`"
     ]
    }
   ],
   "source": [
    "url = \"https://www.jesuismort.com/tombe/albert-camus#biographie\"\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "loader = UnstructuredURLLoader(urls=[url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abrege-9TtSrW0h-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
